{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alheir/22-67-neural-networks/blob/main/tp_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "66aAnzAV_hq6"
      },
      "outputs": [],
      "source": [
        "import os, re, csv, math, codecs, logging\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import pickle\n",
        "import gdown\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
        "class_num = 20"
      ],
      "metadata": {
        "id": "bq2K-KNtLacL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# descargamos los embeddings de palabras de Fasttext para inglés y descomprimimos el archivo.\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!unzip wiki-news-300d-1M.vec.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8VHcRGiLARi",
        "outputId": "e09d3beb-4856-410e-e790-2e12c0eec104"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-29 01:36:40--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.14, 3.163.189.108, 3.163.189.51, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M   130MB/s    in 6.6s    \n",
            "\n",
            "2024-06-29 01:36:46 (98.3 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n",
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cargamos los embeddings de palabras\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open('wiki-news-300d-1M.vec', encoding='utf-8')\n",
        "\n",
        "for line in f:\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print(f'found {len(embeddings_index)} word vectors')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc_N4ScILTdp",
        "outputId": "a8a7c66d-27fd-4ad4-975d-5c1c11c478bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading word embeddings...\n",
            "found 999995 word vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instanciamos el tokenizador\n",
        "token = Tokenizer(num_words=30000,\n",
        "                filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "                lower=True,\n",
        "                split=' ',\n",
        "                char_level=False,\n",
        "                oov_token=\"UNK\",\n",
        "                document_count=0)"
      ],
      "metadata": {
        "id": "WBzcDHYXMEEL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fiteamos el tokenizador\n",
        "token.fit_on_texts(newsgroups_train.data)"
      ],
      "metadata": {
        "id": "hn_6uPC5MZEZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtenemos los diccionarios idx2word y word2idx\n",
        "reverse_dictionary = token.index_word\n",
        "dictionary = dict([(value, key) for (key, value) in reverse_dictionary.items()])\n",
        "# CHECK QUE EMPIEZA POR 0"
      ],
      "metadata": {
        "id": "2ygf-uVlL46e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cargamos en una matriz los embeddings de las palabras\n",
        "# presentes en el vocabulario\n",
        "embed_dim=300\n",
        "num_words=len(dictionary)+1\n",
        "embedding_matrix=np.zeros([num_words,embed_dim])\n",
        "for word, idx in dictionary.items():\n",
        "  if idx <= num_words and word in embeddings_index:\n",
        "    embedding_matrix[idx,:]=embeddings_index[word]"
      ],
      "metadata": {
        "id": "UFWmXJRGMeXK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ajCS18eYBwA",
        "outputId": "a92f4885-b619-426f-9b72-e599da61a7e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105374, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# se tokenizan los textos\n",
        "train_sequences=token.texts_to_sequences(newsgroups_train.data)\n",
        "test_sequences=token.texts_to_sequences(newsgroups_test.data)"
      ],
      "metadata": {
        "id": "fGYvFbYwNjfB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En este punto seleccionamos el tamaño de contexto a procesar en la variable `max_len`\n",
        "max_len=500\n",
        "train_sequences=pad_sequences(train_sequences,maxlen=max_len)\n",
        "test_sequences=pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "OkV9rt_9NpKk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Bidirectional, LSTM, Dense, Embedding, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "QqLNwlPsUSJe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "# la primera capa es de embedding entrenable. Recordar que se puede variar el tamaño\n",
        "# del embedding a entrenar\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embed_dim, weights=[embedding_matrix], input_shape=(None,), trainable = False))\n",
        "\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "# model.add(Dropout(0.2))\n",
        "\n",
        "model.add(LSTM(100))\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Predicción de clasificación con softmax\n",
        "# La salida es del tamaño del vocabulario\n",
        "model.add(Dense(class_num, activation='softmax'))\n",
        "\n",
        "\n",
        "# Clasificación multiple categórica --> loss = categorical_crossentropy\n",
        "# notar que usamos la versión Sparse para utilizar sólo índices en lugar de OHE\n",
        "model.compile(loss=SparseCategoricalCrossentropy(), optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AVcocHjTcRt",
        "outputId": "31edcefa-e126-4cd9-cccf-f721ac77c281"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 300)         31612200  \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, None, 100)         160400    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 20)                2020      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31855020 (121.52 MB)\n",
            "Trainable params: 242820 (948.52 KB)\n",
            "Non-trainable params: 31612200 (120.59 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\",\n",
        "    min_delta=0,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode=\"max\",\n",
        "    baseline=None,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0,\n",
        ")\n",
        "\n",
        "history = model.fit(train_sequences, newsgroups_train.target,\n",
        "                    batch_size=128,\n",
        "                    epochs=100,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stopping]\n",
        "                    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkWOLsrOVAiz",
        "outputId": "eb1a3d25-1bbb-42da-fcde-d2e8dff28a37"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "71/71 [==============================] - 14s 95ms/step - loss: 2.7591 - accuracy: 0.1256 - val_loss: 2.5259 - val_accuracy: 0.1467\n",
            "Epoch 2/100\n",
            "71/71 [==============================] - 5s 73ms/step - loss: 2.3423 - accuracy: 0.2098 - val_loss: 2.1877 - val_accuracy: 0.2479\n",
            "Epoch 3/100\n",
            "71/71 [==============================] - 5s 75ms/step - loss: 2.1109 - accuracy: 0.2806 - val_loss: 2.1504 - val_accuracy: 0.2550\n",
            "Epoch 4/100\n",
            "71/71 [==============================] - 5s 70ms/step - loss: 1.9196 - accuracy: 0.3412 - val_loss: 1.8809 - val_accuracy: 0.3389\n",
            "Epoch 5/100\n",
            "71/71 [==============================] - 5s 69ms/step - loss: 1.8044 - accuracy: 0.3838 - val_loss: 1.7261 - val_accuracy: 0.4008\n",
            "Epoch 6/100\n",
            "71/71 [==============================] - 5s 73ms/step - loss: 1.7320 - accuracy: 0.4085 - val_loss: 1.6613 - val_accuracy: 0.4136\n",
            "Epoch 7/100\n",
            "71/71 [==============================] - 5s 73ms/step - loss: 1.6419 - accuracy: 0.4293 - val_loss: 1.6734 - val_accuracy: 0.4397\n",
            "Epoch 8/100\n",
            "71/71 [==============================] - 5s 73ms/step - loss: 1.6384 - accuracy: 0.4394 - val_loss: 1.5598 - val_accuracy: 0.4600\n",
            "Epoch 9/100\n",
            "71/71 [==============================] - 5s 68ms/step - loss: 1.5673 - accuracy: 0.4552 - val_loss: 1.7709 - val_accuracy: 0.3836\n",
            "Epoch 10/100\n",
            "71/71 [==============================] - 5s 69ms/step - loss: 1.4933 - accuracy: 0.4841 - val_loss: 1.5210 - val_accuracy: 0.4631\n",
            "Epoch 11/100\n",
            "71/71 [==============================] - 5s 71ms/step - loss: 1.5033 - accuracy: 0.4795 - val_loss: 1.4601 - val_accuracy: 0.4839\n",
            "Epoch 12/100\n",
            "71/71 [==============================] - 5s 70ms/step - loss: 1.4647 - accuracy: 0.5012 - val_loss: 1.6227 - val_accuracy: 0.4512\n",
            "Epoch 13/100\n",
            "71/71 [==============================] - 5s 75ms/step - loss: 1.4357 - accuracy: 0.5139 - val_loss: 1.4715 - val_accuracy: 0.4949\n",
            "Epoch 14/100\n",
            "71/71 [==============================] - 6s 88ms/step - loss: 1.3831 - accuracy: 0.5344 - val_loss: 1.4911 - val_accuracy: 0.4998\n",
            "Epoch 15/100\n",
            "71/71 [==============================] - 6s 81ms/step - loss: 1.6043 - accuracy: 0.4886 - val_loss: 1.4934 - val_accuracy: 0.5104\n",
            "Epoch 16/100\n",
            "71/71 [==============================] - 5s 75ms/step - loss: 1.3574 - accuracy: 0.5460 - val_loss: 1.4462 - val_accuracy: 0.5042\n",
            "Epoch 17/100\n",
            "71/71 [==============================] - 5s 75ms/step - loss: 1.3266 - accuracy: 0.5606 - val_loss: 1.4476 - val_accuracy: 0.5175\n",
            "Epoch 18/100\n",
            "71/71 [==============================] - 5s 76ms/step - loss: 1.3165 - accuracy: 0.5618 - val_loss: 1.3705 - val_accuracy: 0.5272\n",
            "Epoch 19/100\n",
            "71/71 [==============================] - 5s 72ms/step - loss: 1.2724 - accuracy: 0.5763 - val_loss: 1.3171 - val_accuracy: 0.5572\n",
            "Epoch 20/100\n",
            "71/71 [==============================] - 5s 69ms/step - loss: 1.2338 - accuracy: 0.5845 - val_loss: 1.3220 - val_accuracy: 0.5475\n",
            "Epoch 21/100\n",
            "71/71 [==============================] - 5s 73ms/step - loss: 1.2066 - accuracy: 0.5977 - val_loss: 1.4290 - val_accuracy: 0.5444\n",
            "Epoch 22/100\n",
            "71/71 [==============================] - 5s 72ms/step - loss: 1.1948 - accuracy: 0.6057 - val_loss: 1.4169 - val_accuracy: 0.5316\n",
            "Epoch 23/100\n",
            "71/71 [==============================] - 5s 76ms/step - loss: 1.1755 - accuracy: 0.6148 - val_loss: 1.2739 - val_accuracy: 0.5771\n",
            "Epoch 24/100\n",
            "71/71 [==============================] - 5s 71ms/step - loss: 1.1564 - accuracy: 0.6182 - val_loss: 1.3299 - val_accuracy: 0.5643\n",
            "Epoch 25/100\n",
            "71/71 [==============================] - 5s 75ms/step - loss: 1.1366 - accuracy: 0.6209 - val_loss: 1.2394 - val_accuracy: 0.6005\n",
            "Epoch 26/100\n",
            "71/71 [==============================] - 5s 74ms/step - loss: 1.1108 - accuracy: 0.6332 - val_loss: 1.2957 - val_accuracy: 0.5780\n",
            "Epoch 27/100\n",
            "71/71 [==============================] - 5s 74ms/step - loss: 1.0932 - accuracy: 0.6415 - val_loss: 1.2857 - val_accuracy: 0.5824\n",
            "Epoch 28/100\n",
            "71/71 [==============================] - 5s 74ms/step - loss: 1.0855 - accuracy: 0.6447 - val_loss: 1.2371 - val_accuracy: 0.5939\n",
            "Epoch 29/100\n",
            "71/71 [==============================] - 5s 72ms/step - loss: 1.0523 - accuracy: 0.6578 - val_loss: 1.2510 - val_accuracy: 0.5983\n",
            "Epoch 30/100\n",
            "71/71 [==============================] - 6s 78ms/step - loss: 1.0361 - accuracy: 0.6603 - val_loss: 1.2992 - val_accuracy: 0.5780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(model.predict(test_sequences), axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I49DEARTqd4k",
        "outputId": "29a723e9-122a-4936-aec5-186ead123a3f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "236/236 [==============================] - 4s 17ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred.shape)\n",
        "print(newsgroups_test.target.shape)\n",
        "\n",
        "print(y_pred)\n",
        "print(newsgroups_test.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYxTmJoOq8hF",
        "outputId": "e7757a82-09ab-4098-fadb-864e7a22f7d3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7532,)\n",
            "(7532,)\n",
            "[ 9  5  9 ...  9  6 15]\n",
            "[ 7  5  0 ...  9  6 15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix"
      ],
      "metadata": {
        "id": "gJwvYRCwu9Ue"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f1_score(newsgroups_test.target, y_pred, average='micro'))\n",
        "print(f1_score(newsgroups_test.target, y_pred, average='macro'))\n",
        "print(f1_score(newsgroups_test.target, y_pred, average='weighted'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KDxPwgfsEfO",
        "outputId": "96e74019-9fc5-42ea-a023-8777b2f182ff"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5650557620817844\n",
            "0.5409683424487132\n",
            "0.5551654432896305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_test = f1_score(newsgroups_test.target, y_pred, average='weighted')\n",
        "recall_score_test = recall_score(newsgroups_test.target, y_pred, average='weighted')\n",
        "precision_score_test = precision_score(newsgroups_test.target, y_pred, average='weighted')"
      ],
      "metadata": {
        "id": "H1-dVFH4tf-p"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'F1-score en test: {f1_score_test}')\n",
        "print(f'Recall en test: {recall_score_test}')\n",
        "print(f'Precision en test: {precision_score_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYTk5SQnqxPF",
        "outputId": "01633525-fb90-491e-af4d-e813c0a78d27"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-score en test: 0.5551654432896305\n",
            "Recall en test: 0.5650557620817844\n",
            "Precision en test: 0.5729787432277426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Tokenizacion: opciones\n",
        "Elman, LSTM, GRU\n",
        "Bidireccional\n",
        "Tamaño de capas y cantidad\n",
        "Dropout\n",
        "RMSProp, ADAM\n",
        "BATCH_SIZE\n",
        "Unloop\n",
        "TPU?\n",
        "Embedding entrenable\n",
        "Forma de colapsar las secuencias\n",
        "Reduccion de dimensionalidad embedding\n",
        "'''"
      ],
      "metadata": {
        "id": "6usD8n3bYd36"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}